{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g7SXaLXTUjSv"
      ],
      "authorship_tag": "ABX9TyOr+kOtXmiWXPhCzCtjw6bW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HagarIbrahiem/Learning_purposes/blob/main/Handle_Missing_Values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google drive for Datasets"
      ],
      "metadata": {
        "id": "4EWytsC6MMrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ9Y-siRLnrD",
        "outputId": "2faa1b34-d048-4eba-c120-8eb770ad88bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/'My Drive'/ML_Process_Data_Files/Section_5_Data_Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cR3jpAjLsqA",
        "outputId": "32b853ef-7254-4470-d92c-d44229e0e157"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clv_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"drive/My Drive/ML_Process_Data_Files/Section_5_Data_Preprocessing/clv_data.csv\")\n",
        "\n",
        "df['lifetime_value'] = df['purchases'] * 20\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C7ohVDhULsuU",
        "outputId": "3274ceb3-addf-449c-82e7-f0195859dfc5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  id   age  gender  income  days_on_platform           city  \\\n",
              "0           0   0   NaN    Male  126895              14.0  San Francisco   \n",
              "1           1   1   NaN    Male  161474              14.0          Tokyo   \n",
              "2           2   2  24.0    Male  104723              34.0         London   \n",
              "3           3   3  29.0    Male   43791              28.0         London   \n",
              "4           4   4  18.0  Female  132181              26.0         London   \n",
              "\n",
              "   purchases  lifetime_value  \n",
              "0          0               0  \n",
              "1          0               0  \n",
              "2          1              20  \n",
              "3          2              40  \n",
              "4          2              40  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a46688c1-81f3-4ab8-b2a9-bdf49e7c888b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>income</th>\n",
              "      <th>days_on_platform</th>\n",
              "      <th>city</th>\n",
              "      <th>purchases</th>\n",
              "      <th>lifetime_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>126895</td>\n",
              "      <td>14.0</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>161474</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>104723</td>\n",
              "      <td>34.0</td>\n",
              "      <td>London</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>43791</td>\n",
              "      <td>28.0</td>\n",
              "      <td>London</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>132181</td>\n",
              "      <td>26.0</td>\n",
              "      <td>London</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a46688c1-81f3-4ab8-b2a9-bdf49e7c888b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a46688c1-81f3-4ab8-b2a9-bdf49e7c888b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a46688c1-81f3-4ab8-b2a9-bdf49e7c888b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nullable values imputaions\n",
        "\n",
        "\n",
        "There is no thump rule to handle missing values in a particular manner, the method which gets a robust model with the best performance. One can use various methods on different features depending on how and what the data is about. Having domain knowledge about the dataset is important, which can give an insight into how to preprocess the data and handle missing values.\n"
      ],
      "metadata": {
        "id": "XhU9RpCkfxMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun containts percentage of null values per column"
      ],
      "metadata": {
        "id": "AiFDVwVoNA_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nulls_summary_table(df):\n",
        "    \"\"\"\n",
        "    Returns a summary table showing null value counts and percentage\n",
        "    \n",
        "    Parameters:\n",
        "    df (DataFrame): Dataframe to check\n",
        "    \n",
        "    Returns:\n",
        "    null_values (DataFrame)\n",
        "    \"\"\"\n",
        "    null_values = pd.DataFrame(df.isnull().sum())\n",
        "    null_values[1] = (null_values[0]/len(df) ) *100\n",
        "    null_values.columns = ['null_count','null_pct']\n",
        "    return null_values\n",
        "\n",
        "nulls_summary_table(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "WgPSbO2xLsyt",
        "outputId": "63de7266-ded7-48b4-e0e5-30aed3b18225"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  null_count  null_pct\n",
              "Unnamed: 0                 0      0.00\n",
              "id                         0      0.00\n",
              "age                     2446     48.92\n",
              "gender                     0      0.00\n",
              "income                     0      0.00\n",
              "days_on_platform         141      2.82\n",
              "city                       0      0.00\n",
              "purchases                  0      0.00\n",
              "lifetime_value             0      0.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c092f615-a282-45c9-8702-ed2e9417b10d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>null_count</th>\n",
              "      <th>null_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>2446</td>\n",
              "      <td>48.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>days_on_platform</th>\n",
              "      <td>141</td>\n",
              "      <td>2.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purchases</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lifetime_value</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c092f615-a282-45c9-8702-ed2e9417b10d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c092f615-a282-45c9-8702-ed2e9417b10d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c092f615-a282-45c9-8702-ed2e9417b10d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIRST :Drop Null Values**"
      ],
      "metadata": {
        "id": "g9h3ITMkkDUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dffierence between delete row and column"
      ],
      "metadata": {
        "id": "tdf7hFrvHcbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "print(df2.isnull().sum().sum())\n",
        "\n",
        "\n",
        "\n",
        "# drop entire column if it has so many null values \n",
        "df_deleterow = df2.drop( ['age'] , axis=1)                               ### see difference between dDROPNA row , DROP column\n",
        "print(df_deleterow.isnull().sum().sum())\n",
        "\n",
        "\n",
        "\n",
        "# drop entire row if it has so many null values \n",
        "df_deleterow = df2.dropna(axis=0)\n",
        "print(df_deleterow.isnull().sum().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "028NUqOZFWxB",
        "outputId": "357a05df-285a-478d-e47f-ad37f0c1b57a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2587\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_df = df.copy()\n",
        "drop_df = drop_df.dropna()\n",
        "\n",
        "\n",
        "X_d = drop_df[['age','days_on_platform','income']]\n",
        "y_d = drop_df['lifetime_value']\n",
        "\n",
        "\n",
        "X_train_d = X_d[:4000]\n",
        "y_train_d = y_d[:4000]\n",
        "\n",
        "X_test_d = X_d[1000:]\n",
        "y_test_d = y_d[1000:]"
      ],
      "metadata": {
        "id": "WBw2r66UkFwv"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECOND: replacing with an arbbitary value**\n",
        "\n",
        "in case you have an educated guess about the missing value "
      ],
      "metadata": {
        "id": "eOPb_MxdHoKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arb_df = df.copy()\n",
        "print (arb_df.isnull().sum().sum())\n",
        "arb_df['age'] = arb_df['age'].fillna(50)\n",
        "print (arb_df.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7TjlFIaHvit",
        "outputId": "65ab8281-c4c4-48f5-bbd9-e826dc4d381a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2587\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THIRD: Mean/Median/Mode Imputation**\n",
        "\n",
        "The next is mean/median/mode imputation. We can use the native numpy functions for the mean and median. We can use scipy for the mode. Then, pandas as a native fillna method we can use to impute the nulls with the mean/median/mode:\n",
        "\n",
        "there are tow ways to impute with Mean/Median/Mode \n",
        "1- Pandas + Numpy\n",
        "2- Sklearn by using SimpleImputer Univaraiate Approcach "
      ],
      "metadata": {
        "id": "QMHgxgToRJkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_df = df.copy()\n",
        "\n",
        "X_m = m_df[['age','days_on_platform','income']]\n",
        "y_m = m_df['lifetime_value']\n",
        "\n",
        "\n",
        "X_train_m = X_m[:4000]\n",
        "y_train_m = y_m[:4000]\n",
        "\n",
        "X_test_m = X_m[1000:]\n",
        "y_test_m = y_m[1000:]"
      ],
      "metadata": {
        "id": "m3hKgfjvLs7E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using Pandas + Numby"
      ],
      "metadata": {
        "id": "g7SXaLXTUjSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "## Mean\n",
        "X_train_m.loc[:,'age'] = X_train_m['age'].fillna(np.mean(X_train_m['age']))\n",
        "X_test_m.loc[:,'age'] = X_test_m['age'].fillna(np.mean(X_train_m['age'])) ## Cannot use training dataset to impute\n",
        "\n",
        "X_train_m.loc[:,'days_on_platform'] = X_train_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform']))\n",
        "X_test_m.loc[:,'days_on_platform'] = X_test_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform'])) ## Cannot use training dataset to impute\n",
        "\n",
        "## Median\n",
        "X_train_m.loc[:,'age'] = X_train_m['age'].fillna(np.median(X_train_m['age']))\n",
        "\n",
        "## Mode\n",
        "X_train_m.loc[:,'age'] = X_train_m['age'].fillna(stats.mode(X_train_m['age'])[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ6_4l1bLs_l",
        "outputId": "a7a786be-97b0-40ae-b782-fd258c2da183"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(ilocs[0], value, pi)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using sklearn - simple imputer"
      ],
      "metadata": {
        "id": "6BXhxEsXP_-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "df_simpleImp = df.copy ()\n",
        "\n",
        "_SimpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean' )\n",
        "df_simpleImp.age = _SimpleImputer.fit_transform(df_simpleImp['age'].values.reshape(-1,1))[:,0]\n",
        "\n",
        "df_simpleImp.isnull().sum()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYKsWuuYQC8H",
        "outputId": "5343429c-e3fa-40f8-e74b-a1952d27808e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0            0\n",
              "id                    0\n",
              "age                   0\n",
              "gender                0\n",
              "income                0\n",
              "days_on_platform    141\n",
              "city                  0\n",
              "purchases             0\n",
              "lifetime_value        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FORTH: backword fill (using next value) OR forward fill (using previous value) OR Interploation (average of previous and next)**"
      ],
      "metadata": {
        "id": "ZRxT9QgPKaU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "my_df = pd.Series(range(10))\n",
        "my_df[2:5] = np.nan\n",
        "my_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOY9uKAwKaoL",
        "outputId": "f1b93f8b-bb64-4e9e-e662-4ed6c481fdb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    NaN\n",
              "3    NaN\n",
              "4    NaN\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.fillna(method='ffill')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3cw5Mi3LdGO",
        "outputId": "6fd03fb8-b256-4bc4-aa89-dc372dea0974"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    1.0\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.fillna(method='bfill')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwmfjFgXLwaS",
        "outputId": "770f8d23-b7bc-41ec-ee4c-542580d38dd2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    5.0\n",
              "3    5.0\n",
              "4    5.0\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIFTH : Interploations**"
      ],
      "metadata": {
        "id": "oVw7uDPUONbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##1- Linear Interpolation defualt method is LINEAR \n",
        "# It estimates the unknown value in the same increasing order from previous values\n",
        "my_df.interpolate() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvTVrpgLy9S",
        "outputId": "c7391b6d-e00d-484a-f3d4-362b1dd29365"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    2.0\n",
              "3    3.0\n",
              "4    4.0\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2- Polynomial Interpolation\n",
        "#In Polynomial Interpolation you need to specify an order. \n",
        "#It means that polynomial interpolation is filling missing values with the lowest possible degree that passes through available data points.\n",
        "# The polynomial Interpolation curve is like the trigonometric sin curve or assumes it like a parabola shape. \n",
        "my_df.interpolate(method=\"polynomial\", order=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9kNgBSWNGk7",
        "outputId": "e9057492-b236-4d2a-f849-9b8ffa910d69"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    2.0\n",
              "3    3.0\n",
              "4    4.0\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3- Interpolation through Padding (act like Forwardfill)\n",
        "# Interpolation with help of padding simply means filling missing values with the same value present above them in the dataset.\n",
        "# If the missing value is in the first row then this method will not work.\n",
        "# While using this technique you also need to specify the limit which means how many NaN values to fill.\n",
        "my_df.interpolate(method=\"pad\", limit=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52qCi9tDNlnC",
        "outputId": "264b795a-13bf-4639-c38c-6738c3f53318"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    NaN\n",
              "5    5.0\n",
              "6    6.0\n",
              "7    7.0\n",
              "8    8.0\n",
              "9    9.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIXTH: More complicated imputation technique: Multiple Imputation / MultiVaraite Approach as it use multiple features to impute missing value**\n",
        "\n",
        "1-Regression Imputation (linear and forests)\n",
        "\n",
        "2- Nearest Neighbor Imputation\n",
        "\n",
        "\n",
        "Multiple imputation has a few different estimators, using the `estimator` argument:\n",
        "\n",
        "- `BayesianRidge`: Regularized Linear Regression\n",
        "\n",
        "- `RandomForestRegressor`: Random Forest Model. Mimics missForest in the R language.\n",
        "\n",
        "We'll go over how these estimators work in the next course: ML Algorithms. \n",
        "\n",
        "The `missing_values` argument is a placeholder for the data type of the missing values you want to impute. \n",
        "\n",
        "It's important to use `add_indicatorbool` as it'll create a placeholder indicating that you've imputed a missing value. This is important, because there could be patterns behind how a value is missing. Adding an indicator would allow you to keep track of where you made an imputation. Plus, it could also add signal into your model. \n",
        "\n",
        "`max_iter`: The number of iteration rounds."
      ],
      "metadata": {
        "id": "kJOXQZpjUmR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "\n",
        "## Regression Imputation \n",
        "\n",
        "r_df = df.copy()\n",
        "\n",
        "X_r = r_df[['age','days_on_platform','income']]\n",
        "y_r = r_df['lifetime_value']\n",
        "\n",
        "\n",
        "X_train_r = X_r[:4000]\n",
        "y_train_r = y_r[:4000]\n",
        "\n",
        "X_test_r = X_r[1000:]\n",
        "y_test_r = y_r[1000:]\n",
        "\n",
        "imp = IterativeImputer ( estimator=LinearRegression(), max_iter=10 , random_state= 0 \n",
        "                        , add_indicator=True) #add_indicator add column to indicate if the value in imputed or not , in case null values are following patterns\n",
        "\n",
        "# use 'days_on_platform','income' to predict 'age' , and use 'age' and 'income' to predict 'days_on_platform'\n",
        "imp.fit(X_train_r)\n",
        "\n",
        "X_train_r = imp.transform(X_train_r)\n",
        "X_test_r = imp.transform (X_test_r)"
      ],
      "metadata": {
        "id": "lMYG7ViyLtHc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r = pd.DataFrame(X_train_r)\n",
        "X_train_r.columns = X_train_r.columns\n",
        "\n",
        "X_test_r = pd.DataFrame(X_test_r)\n",
        "X_test_r.columns = X_test_r.columns\n",
        "\n",
        "df_r = pd.concat([X_train_r , X_test_r] , axis= 0)"
      ],
      "metadata": {
        "id": "-K5kS4dQLtLU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl8R2F70LtOr",
        "outputId": "7ad8ef62-2997-4242-db62-0f215b187d7b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest Neighbor Imputation**\n",
        "\n",
        " you can also use nearest neighbors imputation. Nearest neighbor imputation essentially uses a K-Nearest Neighbors algorithm to find the most similar data points, to impute the null values.\n",
        "\n",
        "\n",
        "`missing_values`: This is the type of null value you want to impute. Typically, this is NaN, but it could be float or whichever you decide.\n",
        "\n",
        "`n_neighbors`: The number of neighbors to use for imputation. You can add more or less. Fewer neighbors can lead to overfitting. Larger numbers will lose some precision.\n",
        "\n",
        "`weights`: Pick how you want to weight all points in each neighborhood. There are two typical ways: 'uniform' or 'distance'. Uniform is equal weighting. Distance is weighted by the distance from the point.\n",
        "\n",
        "`callable` : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
        "metric: The distance metric used to search for neighbors. The default is euclidean.\n",
        "\n",
        "`add_indicator`: This will add a dummy feature 0 or 1 if the value was imputed, similar to add_indicatorbool."
      ],
      "metadata": {
        "id": "SwKSF3T5fdQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knnImp = KNNImputer (weights='uniform' , n_neighbors=5) # for this null values , we will find the 5 closest values to get the impuation   \n",
        "\n",
        "knnImp.fit(X_train_r)\n",
        "\n",
        "X_train_k = knnImp.transform(X_train_r)\n",
        "X_test_k = knnImp.transform(X_test_r)\n",
        "\n",
        "y_train_k = y_train_r.copy()\n",
        "y_test_k = y_test_r.copy()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erFO-0T5LtSo",
        "outputId": "407825f5-1b25-4e64-c95e-a42ce35600e9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.05480927e+01, 1.40000000e+01, 1.26895000e+05, 1.00000000e+00,\n",
              "        0.00000000e+00],\n",
              "       [3.08481372e+01, 1.40000000e+01, 1.61474000e+05, 1.00000000e+00,\n",
              "        0.00000000e+00],\n",
              "       [2.40000000e+01, 3.40000000e+01, 1.04723000e+05, 0.00000000e+00,\n",
              "        0.00000000e+00],\n",
              "       ...,\n",
              "       [4.60000000e+01, 5.20000000e+01, 5.14320000e+04, 0.00000000e+00,\n",
              "        0.00000000e+00],\n",
              "       [1.40000000e+01, 3.70000000e+01, 4.94090000e+04, 0.00000000e+00,\n",
              "        0.00000000e+00],\n",
              "       [3.08868792e+01, 2.30000000e+01, 1.49963000e+05, 1.00000000e+00,\n",
              "        0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use attripute of (add_indicator=True)**"
      ],
      "metadata": {
        "id": "mzid5AROU45H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X = pd.DataFrame({'Age':[20, 30, 10, np.nan, 10]})\n",
        "\n",
        "imputer = SimpleImputer(add_indicator=True)\n",
        "imputer.fit_transform(X)\n",
        "\n",
        "\n",
        "# ‘1’ indicates that the corresponding value was missing and ‘0’ indicates that the corresponding value was not missing."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g32oo-vnU69o",
        "outputId": "2111227b-4ce8-4c84-b5bc-96398de86a49"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20. ,  0. ],\n",
              "       [30. ,  0. ],\n",
              "       [10. ,  0. ],\n",
              "       [17.5,  1. ],\n",
              "       [10. ,  0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEVENTH : Imputation using Deep Learning Library — Datawig**"
      ],
      "metadata": {
        "id": "ZL8V__QDco5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datawig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYLc-2BRcyEb",
        "outputId": "6325fa70-331e-4244-d5f4-d3bdb5da7b9a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datawig\n",
            "  Downloading datawig-0.2.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn[alldeps]==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing==3.6.6\n",
            "  Downloading typing-3.6.6-py3-none-any.whl (25 kB)\n",
            "Collecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mxnet==1.4.0\n",
            "  Downloading mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/29.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<1.15.0,>=1.8.2\n",
            "  Downloading numpy-1.14.6.zip (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet==1.4.0->datawig) (2.25.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==0.25.3->datawig) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==0.25.3->datawig) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3->datawig) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (1.24.3)\n",
            "Collecting scipy>=0.17.0\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.7.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.6.2-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.6.1-cp38-cp38-manylinux1_x86_64.whl (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.6.0-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: datawig, numpy\n",
            "  Building wheel for datawig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datawig: filename=datawig-0.2.0-py3-none-any.whl size=72677 sha256=36bc3275b62e548ceddcc22e0094bacb1de18883e7b9f6ceb6393aee6b221f7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/98/7e/0361b6b68a18ee5bb5398f7ab50d54772f8bcf6946a1eb9ef2\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpy: filename=numpy-1.14.6-cp38-cp38-linux_x86_64.whl size=9740431 sha256=763e76c3d1fd2ae48e530a7eee4642f7c9d51bf9aed2b3fb503a67fbb4e5987d\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/81/aa/e309a6725c1cb6f5b37c3c67b74828fd4db0827592ff4a4f85\n",
            "Successfully built datawig numpy\n",
            "Installing collected packages: typing, numpy, graphviz, scipy, pandas, mxnet, scikit-learn, datawig\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n",
            "thinc 8.1.7 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n",
            "statsmodels 0.12.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "spacy 3.4.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n",
            "resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pywavelets 1.4.1 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.\n",
            "pymc 4.1.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pyarrow 9.0.0 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "prophet 1.1.2 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "prophet 1.1.2 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "opencv-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.14.6 which is incompatible.\n",
            "opencv-python-headless 4.7.0.68 requires numpy>=1.17.0; python_version >= \"3.7\", but you have numpy 1.14.6 which is incompatible.\n",
            "opencv-python-headless 4.7.0.68 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.14.6 which is incompatible.\n",
            "opencv-contrib-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.14.6 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "imgaug 0.4.0 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "httpstan 4.6.1 requires numpy<2.0,>=1.16, but you have numpy 1.14.6 which is incompatible.\n",
            "h5py 3.1.0 requires numpy>=1.17.5; python_version == \"3.8\", but you have numpy 1.14.6 which is incompatible.\n",
            "gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.14.6 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "db-dtypes 1.0.5 requires numpy<2.0dev,>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "cvxpy 1.2.3 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.\n",
            "blis 0.7.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.14.6 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.14.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datawig-0.2.0 graphviz-0.8.4 mxnet-1.4.0 numpy-1.14.6 pandas-0.25.3 scikit-learn-0.22.1 scipy-1.5.4 typing-3.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datawig\n",
        "\n",
        "df_train, df_test = datawig.utils.random_split(data)\n",
        "\n",
        "#Initialize a SimpleImputer model\n",
        "imputer = datawig.SimpleImputer(\n",
        "    input_columns=['days_on_platform','income'], # column(s) containing information about the column we want to impute\n",
        "    output_column= 'age', # the column we'd like to impute values for\n",
        "    output_path = 'imputer_model' # stores model data and metrics\n",
        "    )\n",
        "\n",
        "#Fit an imputer model on the train data\n",
        "imputer.fit(train_df=df_train, num_epochs=50)\n",
        "\n",
        "#Impute missing values and return original dataframe with predictions\n",
        "imputed = imputer.predict(df_test)"
      ],
      "metadata": {
        "id": "lFsLxttIdXXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare between different Nullable Techniques**"
      ],
      "metadata": {
        "id": "xjM0HAQ5jy6s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qknvmxyc3WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Drop Null Model\n",
        "clf_n = RandomForestRegressor(random_state=0)\n",
        "clf_n.fit(X_train_d, y_train_d)\n",
        "pred_dropna = clf_n.predict(X_test_d)\n",
        "\n",
        "\n",
        "\n",
        "# Mean Imputation Model\n",
        "clf_m = RandomForestRegressor(random_state=0)\n",
        "clf_m.fit(X_train_m, y_train_m)\n",
        "pred_m = clf_m.predict(X_test_m)\n",
        "\n",
        "# Regression Imputation\n",
        "clf_r = RandomForestRegressor(random_state=0)\n",
        "clf_r.fit(X_train_r, y_train_r)\n",
        "pred_r = clf_r.predict(X_test_r)\n",
        "\n",
        "#Nearest Neighbor Imputation\n",
        "clf_n = RandomForestRegressor(random_state=0)\n",
        "clf_n.fit(X_train_k, y_train_k)\n",
        "pred_k = clf_n.predict(X_test_k)\n",
        "\n",
        "\n",
        "print('Drop Null MAE Score: %.3f' % mean_absolute_error(y_test_d,pred_dropna))\n",
        "print('Mean Impute MAE Score: %.3f' % mean_absolute_error(y_test_m,pred_m))\n",
        "print('Regression MAE Score: %.3f '% mean_absolute_error(y_test_r,pred_r))\n",
        "print('Nearest Neighbor MAE Score: %.3f'% mean_absolute_error(y_test_k,pred_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T87LHV8iLtW8",
        "outputId": "fe6b7583-42b5-41d4-f7c2-63100364537d"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drop Null MAE Score: 7.636\n",
            "Mean Impute MAE Score: 10.828\n",
            "Regression MAE Score: 10.796 \n",
            "Nearest Neighbor MAE Score: 10.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resources**\n",
        "\n",
        "\n",
        "1  [link text](https://learn.365datascience.com/courses/learn-machine-learning-process-a-z/types-of-null-values/)\n",
        "\n",
        "\n",
        "2  [link text](https://www.analyticsvidhya.com/blog/2021/10/handling-missing-value/#:~:text=Types%20Of%20Missing%20Values,Missing%20Not%20At%20Random%20(MNAR))"
      ],
      "metadata": {
        "id": "7zgKEFdUVsun"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBWGUHF0j-Dz"
      },
      "execution_count": 126,
      "outputs": []
    }
  ]
}